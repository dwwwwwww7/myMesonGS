# 量化参数输出说明

## 功能
在训练过程中，每次评估时会自动输出当前的量化参数（LSQ 的 scale 值）和位深配置。

## 输出示例

```
[ITER 1000] Evaluating train: L1 0.0234 PSNR 28.5432

======================================================================
量化参数 [Iteration 1000]
======================================================================

位深配置:
  opacity:   8-bit
  euler:     8-bit
  f_dc:      8-bit
  f_rest_0:  4-bit
  f_rest_1:  4-bit
  f_rest_2:  2-bit
  scale:     10-bit

LSQ 量化参数 (scale 值):
  总量化器数量: 3135 (55维 × 57块)

  维度         | 位深   | 平均scale    | 最小scale    | 最大scale   
  ------------+--------+--------------+--------------+--------------
  opacity      | 8      | 0.012345     | 0.010234     | 0.015678
  euler        | 8      | 0.023456     | 0.019876     | 0.028901
  f_dc         | 8      | 0.034567     | 0.029012     | 0.041234
  f_rest_0     | 4      | 0.045678     | 0.038765     | 0.053210
  f_rest_1     | 4      | 0.056789     | 0.048901     | 0.065432
  f_rest_2     | 2      | 0.067890     | 0.059012     | 0.078901
  scale        | 10     | 0.078901     | 0.069123     | 0.089012
======================================================================
```

## 输出内容说明

### 1. 位深配置
显示每个特征维度使用的量化位数：
- **opacity** (1维): 不透明度
- **euler** (3维): 欧拉角（旋转）
- **f_dc** (3维): SH 系数 DC 分量
- **f_rest_0** (15维): SH 系数 degree 1
- **f_rest_1** (15维): SH 系数 degree 2
- **f_rest_2** (15维): SH 系数 degree 3
- **scale** (3维): 缩放参数

### 2. LSQ 量化参数
显示每个维度的 LSQ scale 参数统计：

- **平均scale**: 该维度所有块的 scale 平均值
- **最小scale**: 该维度所有块的 scale 最小值
- **最大scale**: 该维度所有块的 scale 最大值

### 3. Scale 值的含义

LSQ 的 scale 参数控制量化步长：
```
量化步长 = scale
量化值 = round(x / scale)
反量化值 = 量化值 * scale
```

**Scale 值越小**：
- 量化步长越小
- 量化精度越高
- 但量化范围越小

**Scale 值越大**：
- 量化步长越大
- 量化精度越低
- 但量化范围越大

### 4. 训练过程中的变化

在训练过程中，LSQ 的 scale 参数会自动学习和调整：

- **初始阶段**: scale 值较大，适应数据分布
- **中期**: scale 值逐渐稳定
- **后期**: scale 值微调，优化量化性能

## 如何使用

### 1. 自动输出（训练时）
训练时会自动在每次评估后输出量化参数，无需额外配置。

### 2. 手动调用
也可以在代码中手动调用：

```python
# 在任何地方调用
gaussians.print_quantization_params(iteration=1000)

# 或不指定迭代号
gaussians.print_quantization_params()
```

### 3. 保存到文件
如果想保存量化参数到文件，可以重定向输出：

```bash
python mesongs.py ... > training_log.txt 2>&1
```

然后从 `training_log.txt` 中提取量化参数信息。

## 分析建议

### 1. 检查 scale 值的合理性
- 如果 scale 值过大（> 1.0），可能需要调整初始化
- 如果 scale 值过小（< 0.001），可能导致数值不稳定

### 2. 观察 scale 值的变化趋势
- scale 值应该逐渐收敛
- 如果持续震荡，可能需要降低学习率

### 3. 比较不同维度的 scale 值
- 不同维度的 scale 值应该有差异
- 如果某个维度的 scale 值异常，可能需要检查数据

### 4. 监控最小/最大 scale 的差异
- 如果差异过大，可能需要使用 per-channel 量化
- 如果差异很小，说明量化比较均匀

## 常见问题

### Q: 为什么有些维度的 scale 值相同？
A: 因为使用了相同的位深配置，且数据分布相似。

### Q: scale 值应该在什么范围内？
A: 通常在 0.001 到 1.0 之间，具体取决于数据分布和位深。

### Q: 如何调整 scale 的学习率？
A: 在优化器中为量化参数设置单独的学习率：
```python
optimizer = torch.optim.Adam([
    {'params': model_params, 'lr': 1e-4},
    {'params': quantizer_params, 'lr': 1e-5}  # 更小的学习率
])
```

### Q: 输出太频繁怎么办？
A: 可以添加条件控制输出频率：
```python
if iteration % 100 == 0:  # 每100次迭代输出一次
    scene.gaussians.print_quantization_params(iteration=iteration)
```

## 与 VanillaQuan 的区别

**VanillaQuan**:
- 没有可学习的参数
- 动态计算 scale 和 zero_point
- 不会输出量化参数（因为每次都重新计算）

**LsqQuan (LSQ)**:
- 有可学习的 scale 参数
- scale 参数通过梯度下降优化
- 可以输出和监控 scale 的变化

这就是为什么切换到 LSQ 后可以输出量化参数的原因！
